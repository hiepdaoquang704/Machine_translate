{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3533582,"sourceType":"datasetVersion","datasetId":2125411},{"sourceId":7817074,"sourceType":"datasetVersion","datasetId":4579647}],"dockerImageVersionId":30177,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 0. Import libraries","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install fasttext underthesea nltk ","metadata":{"execution":{"iopub.status.busy":"2024-03-13T15:22:26.311037Z","iopub.execute_input":"2024-03-13T15:22:26.311421Z","iopub.status.idle":"2024-03-13T15:22:38.439398Z","shell.execute_reply.started":"2024-03-13T15:22:26.311312Z","shell.execute_reply":"2024-03-13T15:22:38.438334Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import re\nimport json\nimport string\nimport random\nimport warnings\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import TextVectorization\nfrom tqdm.notebook import tqdm\n\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-13T15:22:38.441571Z","iopub.execute_input":"2024-03-13T15:22:38.441843Z","iopub.status.idle":"2024-03-13T15:22:44.043696Z","shell.execute_reply.started":"2024-03-13T15:22:38.441812Z","shell.execute_reply":"2024-03-13T15:22:44.043118Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os","metadata":{"execution":{"iopub.status.busy":"2024-03-13T15:22:44.044827Z","iopub.execute_input":"2024-03-13T15:22:44.045052Z","iopub.status.idle":"2024-03-13T15:22:44.048744Z","shell.execute_reply.started":"2024-03-13T15:22:44.045024Z","shell.execute_reply":"2024-03-13T15:22:44.047949Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# 1. Preparing data for training","metadata":{}},{"cell_type":"code","source":"data_train_vi = []\ndata_train_en = []\ndata_test2012_vi = []\ndata_test2012_en = []\ndata_test2013_vi = []\ndata_test2013_en = []","metadata":{"execution":{"iopub.status.busy":"2024-03-13T15:22:44.050761Z","iopub.execute_input":"2024-03-13T15:22:44.051031Z","iopub.status.idle":"2024-03-13T15:22:44.068326Z","shell.execute_reply.started":"2024-03-13T15:22:44.050994Z","shell.execute_reply":"2024-03-13T15:22:44.067621Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input/machine-translate-envi/data'):\n    for filename in filenames:\n        path = os.path.join(dirname, filename)\n        if 'train.vi' in filename:\n            with open(path, 'r', encoding='utf-8') as f:\n                data_train_vi.extend(f.readlines())\n        elif 'train.en' in filename:\n            with open(path, 'r', encoding='utf-8') as f:\n                data_train_en.extend(f.readlines())\n        elif 'tst2012.vi' in filename:\n            with open(path, 'r', encoding='utf-8') as f:\n                data_test2012_vi.extend(f.readlines())\n        elif 'tst2012.en' in filename:\n            with open(path, 'r', encoding='utf-8') as f:\n                data_test2012_en.extend(f.readlines())\n        elif 'tst2013.vi' in filename:\n            with open(path, 'r', encoding='utf-8') as f:\n                data_test2013_vi.extend(f.readlines())\n        elif 'tst2013.en' in filename:\n            with open(path, 'r', encoding='utf-8') as f:\n                data_test2013_en.extend(f.readlines())","metadata":{"execution":{"iopub.status.busy":"2024-03-13T15:22:44.069307Z","iopub.execute_input":"2024-03-13T15:22:44.069522Z","iopub.status.idle":"2024-03-13T15:22:44.630655Z","shell.execute_reply.started":"2024-03-13T15:22:44.069497Z","shell.execute_reply":"2024-03-13T15:22:44.629982Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def prepare( sentence):\n        sentence = re.sub(\n        r\"[\\*\\\"“”\\n\\\\…\\+\\-\\/\\=\\(\\)‘•:\\[\\]\\|’\\!;]\", \" \", str(sentence))\n        sentence = re.sub(r\"[ ]+\", \" \", sentence)\n        sentence = re.sub(r\"\\!+\", \"!\", sentence)\n        sentence = re.sub(r\"\\,+\", \",\", sentence)\n        sentence = re.sub(r\"\\?+\", \"?\", sentence)\n        sentence = sentence.lower()\n        return sentence","metadata":{"execution":{"iopub.status.busy":"2024-03-13T15:22:44.631722Z","iopub.execute_input":"2024-03-13T15:22:44.631966Z","iopub.status.idle":"2024-03-13T15:22:44.637682Z","shell.execute_reply.started":"2024-03-13T15:22:44.631931Z","shell.execute_reply":"2024-03-13T15:22:44.637006Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"pattern1 =  r\"[\\*\\\"“”\\n\\\\…\\+\\-\\/\\=\\(\\)‘•:\\[\\]\\|’\\!;]\"","metadata":{"execution":{"iopub.status.busy":"2024-03-13T15:22:44.638913Z","iopub.execute_input":"2024-03-13T15:22:44.639262Z","iopub.status.idle":"2024-03-13T15:22:44.647698Z","shell.execute_reply.started":"2024-03-13T15:22:44.639225Z","shell.execute_reply":"2024-03-13T15:22:44.647010Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data_train_vi=[prepare(sentence) for sentence in data_train_vi]\ndata_train_en=[prepare(sentence) for sentence in data_train_en]\ndata_test2012_vi=[prepare(sentence) for sentence in data_test2012_vi]\n\ndata_test2012_en=[prepare(sentence) for sentence in data_test2012_en]\ndata_test2013_vi=[prepare(sentence) for sentence in data_test2013_vi]\ndata_test2013_en=[prepare(sentence) for sentence in data_test2013_en]","metadata":{"execution":{"iopub.status.busy":"2024-03-13T15:22:44.648705Z","iopub.execute_input":"2024-03-13T15:22:44.648954Z","iopub.status.idle":"2024-03-13T15:22:50.855441Z","shell.execute_reply.started":"2024-03-13T15:22:44.648918Z","shell.execute_reply":"2024-03-13T15:22:50.854576Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"print(data_train_vi[10])\nprint(data_train_en[10])","metadata":{"execution":{"iopub.status.busy":"2024-03-13T15:22:50.856658Z","iopub.execute_input":"2024-03-13T15:22:50.856927Z","iopub.status.idle":"2024-03-13T15:22:50.861886Z","shell.execute_reply.started":"2024-03-13T15:22:50.856893Z","shell.execute_reply":"2024-03-13T15:22:50.861140Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"mỗi năm , hơn 15,000 nhà khoa học đến san francisco để tham dự hội nghị này . \nover 15,000 scientists go to san francisco every year for that . \n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 2. Vectorizing the text data and format our datasets","metadata":{}},{"cell_type":"code","source":"strip_chars = string.punctuation\nstrip_chars = strip_chars.replace('[', '')\nstrip_chars = strip_chars.replace(']', '')\n\nvocab_size = 15000\nsequence_length = 100\nbatch_size = 128\n\ndef custom_standardization(input_string):\n    lowercase = tf.strings.lower(input_string)\n    return tf.strings.regex_replace(lowercase, '[%s]' % re.escape(strip_chars), '')\n\nen_vectorization = TextVectorization(\n    max_tokens=vocab_size,\n    output_mode='int',\n    output_sequence_length=sequence_length\n)\nvi_vectorization = TextVectorization(\n    max_tokens=vocab_size,\n    output_mode='int',\n    output_sequence_length=sequence_length + 1,\n    standardize=custom_standardization\n)\n\nen_vectorization.adapt(data_train_en)\nvi_vectorization.adapt(data_train_vi)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T15:22:50.864813Z","iopub.execute_input":"2024-03-13T15:22:50.865453Z","iopub.status.idle":"2024-03-13T15:23:09.955005Z","shell.execute_reply.started":"2024-03-13T15:22:50.865412Z","shell.execute_reply":"2024-03-13T15:23:09.954352Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def format_dataset(en, vi):\n    en = en_vectorization(en)\n    vi = vi_vectorization(vi)\n    return ({\n        'encoder_inputs': en,\n        'decoder_inputs': vi[:, :-1]\n    }, vi[:, 1:])\n\ndef make_dataset(en_texts,vi_texts):\n    \n    dataset = tf.data.Dataset.from_tensor_slices((en_texts, vi_texts))\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.map(format_dataset)\n    \n    return dataset.shuffle(2048).prefetch(16).cache()\n\ntrain_ds = make_dataset(data_train_en,data_train_vi)\nval_ds = make_dataset(data_test2012_en,data_test2012_vi)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T15:23:09.956280Z","iopub.execute_input":"2024-03-13T15:23:09.956514Z","iopub.status.idle":"2024-03-13T15:23:11.549670Z","shell.execute_reply.started":"2024-03-13T15:23:09.956486Z","shell.execute_reply":"2024-03-13T15:23:11.549025Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"for inputs, targets in train_ds.take(1):\n    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n    print(f\"targets.shape: {targets.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-13T15:23:11.550780Z","iopub.execute_input":"2024-03-13T15:23:11.551007Z","iopub.status.idle":"2024-03-13T15:23:12.838544Z","shell.execute_reply.started":"2024-03-13T15:23:11.550979Z","shell.execute_reply":"2024-03-13T15:23:12.837740Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"inputs[\"encoder_inputs\"].shape: (128, 100)\ninputs[\"decoder_inputs\"].shape: (128, 100)\ntargets.shape: (128, 100)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 3. Building the model","metadata":{}},{"cell_type":"code","source":"class TransformerEncoder(layers.Layer):\n    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n        super(TransformerEncoder, self).__init__(**kwargs)\n        self.embed_dim = embed_dim\n        self.dense_dim = dense_dim\n        self.num_heads = num_heads\n        self.attention = layers.MultiHeadAttention(\n            num_heads=num_heads, key_dim=embed_dim\n        )\n        self.dense_proj = keras.Sequential(\n            [layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n        )\n        self.layernorm_1 = layers.LayerNormalization()\n        self.layernorm_2 = layers.LayerNormalization()\n        self.supports_masking = True\n\n    def call(self, inputs, mask=None):\n        if mask is not None:\n            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\"int32\")\n        attention_output = self.attention(\n            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n        )\n        proj_input = self.layernorm_1(inputs + attention_output)\n        proj_output = self.dense_proj(proj_input)\n        return self.layernorm_2(proj_input + proj_output)\n\n    def get_config(self):\n        config = super().get_config().copy()\n        config.update({\n            'embed_dim': self.embed_dim,\n            'dense_dim': self.dense_dim,\n            'num_heads': self.num_heads\n        })\n        return config\n\nclass PositionalEmbedding(layers.Layer):\n    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n        super(PositionalEmbedding, self).__init__(**kwargs)\n        self.token_embeddings = layers.Embedding(\n            input_dim=vocab_size, output_dim=embed_dim\n        )\n        self.position_embeddings = layers.Embedding(\n            input_dim=sequence_length, output_dim=embed_dim\n        )\n        self.sequence_length = sequence_length\n        self.vocab_size = vocab_size\n        self.embed_dim = embed_dim\n\n    def call(self, inputs):\n        length = tf.shape(inputs)[-1]\n        positions = tf.range(start=0, limit=length, delta=1)\n        embedded_tokens = self.token_embeddings(inputs)\n        embedded_positions = self.position_embeddings(positions)\n        return embedded_tokens + embedded_positions\n\n    def compute_mask(self, inputs, mask=None):\n        return tf.math.not_equal(inputs, 0)\n    \n    def get_config(self):\n        config = super().get_config().copy()\n        config.update({\n            'sequence_length': self.sequence_length,\n            'vocab_size': self.vocab_size,\n            'embed_dim': self.embed_dim\n        })\n        return config\n\nclass TransformerDecoder(layers.Layer):\n    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n        super(TransformerDecoder, self).__init__(**kwargs)\n        self.embed_dim = embed_dim\n        self.latent_dim = latent_dim\n        self.num_heads = num_heads\n        self.attention_1 = layers.MultiHeadAttention(\n            num_heads=num_heads, key_dim=embed_dim\n        )\n        self.attention_2 = layers.MultiHeadAttention(\n            num_heads=num_heads, key_dim=embed_dim\n        )\n        self.dense_proj = keras.Sequential(\n            [layers.Dense(latent_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n        )\n        self.layernorm_1 = layers.LayerNormalization()\n        self.layernorm_2 = layers.LayerNormalization()\n        self.layernorm_3 = layers.LayerNormalization()\n        self.supports_masking = True\n\n    def call(self, inputs, encoder_outputs, mask=None):\n        causal_mask = self.get_causal_attention_mask(inputs)\n        if mask is not None:\n            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n            padding_mask = tf.minimum(padding_mask, causal_mask)\n\n        attention_output_1 = self.attention_1(\n            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n        )\n        out_1 = self.layernorm_1(inputs + attention_output_1)\n\n        attention_output_2 = self.attention_2(\n            query=out_1,\n            value=encoder_outputs,\n            key=encoder_outputs,\n            attention_mask=padding_mask,\n        )\n        out_2 = self.layernorm_2(out_1 + attention_output_2)\n\n        proj_output = self.dense_proj(out_2)\n        return self.layernorm_3(out_2 + proj_output)\n\n    def get_causal_attention_mask(self, inputs):\n        input_shape = tf.shape(inputs)\n        batch_size, sequence_length = input_shape[0], input_shape[1]\n        i = tf.range(sequence_length)[:, tf.newaxis]\n        j = tf.range(sequence_length)\n        mask = tf.cast(i >= j, dtype=\"int32\")\n        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n        mult = tf.concat(\n            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n            axis=0,\n        )\n        return tf.tile(mask, mult)\n    \n    def get_config(self):\n        config = super().get_config().copy()\n        config.update({\n            'embed_dim': self.embed_dim,\n            'latent_dim': self.latent_dim,\n            'num_heads': self.num_heads\n        })\n        return config","metadata":{"execution":{"iopub.status.busy":"2024-03-13T15:23:12.840015Z","iopub.execute_input":"2024-03-13T15:23:12.840276Z","iopub.status.idle":"2024-03-13T15:23:12.871525Z","shell.execute_reply.started":"2024-03-13T15:23:12.840244Z","shell.execute_reply":"2024-03-13T15:23:12.870876Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"embed_dim = 256\nlatent_dim = 2048\nnum_heads = 8\n\nencoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\nx = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\nencoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\nencoder = keras.Model(encoder_inputs, encoder_outputs)\n\ndecoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\nencoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\nx = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\nx = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\nx = layers.Dropout(0.5)(x)\ndecoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\ndecoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n\ndecoder_outputs = decoder([decoder_inputs, encoder_outputs])\ntransformer = keras.Model(\n    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T15:23:12.872440Z","iopub.execute_input":"2024-03-13T15:23:12.872633Z","iopub.status.idle":"2024-03-13T15:23:13.828756Z","shell.execute_reply.started":"2024-03-13T15:23:12.872597Z","shell.execute_reply":"2024-03-13T15:23:13.828141Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# 4. Training our model","metadata":{}},{"cell_type":"code","source":"print(tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T15:42:36.338533Z","iopub.execute_input":"2024-03-13T15:42:36.338821Z","iopub.status.idle":"2024-03-13T15:42:36.343353Z","shell.execute_reply.started":"2024-03-13T15:42:36.338787Z","shell.execute_reply":"2024-03-13T15:42:36.342541Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"2.6.2\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 20\n\ntransformer.summary()\ntransformer.compile(\n    optimizer=\"rmsprop\", \n    loss=\"sparse_categorical_crossentropy\", \n    metrics=[\"accuracy\"]\n)\nhistory = transformer.fit(train_ds, epochs=epochs, validation_data=val_ds)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T15:47:29.202966Z","iopub.execute_input":"2024-03-13T15:47:29.203298Z","iopub.status.idle":"2024-03-13T17:23:53.892390Z","shell.execute_reply.started":"2024-03-13T15:47:29.203263Z","shell.execute_reply":"2024-03-13T17:23:53.891668Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Model: \"transformer\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nencoder_inputs (InputLayer)     [(None, None)]       0                                            \n__________________________________________________________________________________________________\npositional_embedding (Positiona (None, None, 256)    3865600     encoder_inputs[0][0]             \n__________________________________________________________________________________________________\ndecoder_inputs (InputLayer)     [(None, None)]       0                                            \n__________________________________________________________________________________________________\ntransformer_encoder (Transforme (None, None, 256)    3155456     positional_embedding[0][0]       \n__________________________________________________________________________________________________\nmodel_1 (Functional)            (None, None, 15000)  12980120    decoder_inputs[0][0]             \n                                                                 transformer_encoder[0][0]        \n==================================================================================================\nTotal params: 20,001,176\nTrainable params: 20,001,176\nNon-trainable params: 0\n__________________________________________________________________________________________________\nEpoch 1/20\n1042/1042 [==============================] - 293s 278ms/step - loss: 0.7603 - accuracy: 0.4246 - val_loss: 0.6524 - val_accuracy: 0.4294\nEpoch 2/20\n1042/1042 [==============================] - 289s 277ms/step - loss: 0.7245 - accuracy: 0.4448 - val_loss: 0.6378 - val_accuracy: 0.4426\nEpoch 3/20\n1042/1042 [==============================] - 289s 277ms/step - loss: 0.6992 - accuracy: 0.4609 - val_loss: 0.6310 - val_accuracy: 0.4498\nEpoch 4/20\n1042/1042 [==============================] - 289s 277ms/step - loss: 0.6802 - accuracy: 0.4736 - val_loss: 0.6257 - val_accuracy: 0.4528\nEpoch 5/20\n1042/1042 [==============================] - 289s 278ms/step - loss: 0.6523 - accuracy: 0.4935 - val_loss: 0.6227 - val_accuracy: 0.4566\nEpoch 7/20\n1042/1042 [==============================] - 289s 277ms/step - loss: 0.6406 - accuracy: 0.5021 - val_loss: 0.6221 - val_accuracy: 0.4569\nEpoch 8/20\n1042/1042 [==============================] - 289s 277ms/step - loss: 0.6305 - accuracy: 0.5094 - val_loss: 0.6219 - val_accuracy: 0.4581\nEpoch 9/20\n1042/1042 [==============================] - 289s 277ms/step - loss: 0.6216 - accuracy: 0.5164 - val_loss: 0.6249 - val_accuracy: 0.4563\nEpoch 10/20\n1042/1042 [==============================] - 289s 277ms/step - loss: 0.6134 - accuracy: 0.5228 - val_loss: 0.6246 - val_accuracy: 0.4595\nEpoch 11/20\n1042/1042 [==============================] - 289s 277ms/step - loss: 0.6055 - accuracy: 0.5287 - val_loss: 0.6271 - val_accuracy: 0.4576\nEpoch 12/20\n1042/1042 [==============================] - 289s 277ms/step - loss: 0.5978 - accuracy: 0.5349 - val_loss: 0.6285 - val_accuracy: 0.4581\nEpoch 13/20\n1042/1042 [==============================] - 289s 277ms/step - loss: 0.5903 - accuracy: 0.5404 - val_loss: 0.6297 - val_accuracy: 0.4580\nEpoch 14/20\n1042/1042 [==============================] - 289s 278ms/step - loss: 0.5834 - accuracy: 0.5457 - val_loss: 0.6318 - val_accuracy: 0.4565\nEpoch 15/20\n1042/1042 [==============================] - 289s 278ms/step - loss: 0.5768 - accuracy: 0.5508 - val_loss: 0.6330 - val_accuracy: 0.4572\nEpoch 16/20\n1042/1042 [==============================] - 289s 278ms/step - loss: 0.5707 - accuracy: 0.5558 - val_loss: 0.6351 - val_accuracy: 0.4585\nEpoch 17/20\n1042/1042 [==============================] - 289s 278ms/step - loss: 0.5644 - accuracy: 0.5605 - val_loss: 0.6358 - val_accuracy: 0.4583\nEpoch 18/20\n1042/1042 [==============================] - 289s 278ms/step - loss: 0.5589 - accuracy: 0.5648 - val_loss: 0.6392 - val_accuracy: 0.4583\nEpoch 19/20\n1042/1042 [==============================] - 289s 277ms/step - loss: 0.5529 - accuracy: 0.5690 - val_loss: 0.6398 - val_accuracy: 0.4580\nEpoch 20/20\n1042/1042 [==============================] - 289s 278ms/step - loss: 0.5476 - accuracy: 0.5734 - val_loss: 0.6436 - val_accuracy: 0.4557\n","output_type":"stream"}]},{"cell_type":"code","source":"json.dump(history.history, open('./history.json', 'w'))","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:24:06.417871Z","iopub.execute_input":"2024-03-13T17:24:06.418110Z","iopub.status.idle":"2024-03-13T17:24:06.423026Z","shell.execute_reply.started":"2024-03-13T17:24:06.418066Z","shell.execute_reply":"2024-03-13T17:24:06.422263Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"transformer.save('./best_model.h5')\n","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:44:06.601535Z","iopub.execute_input":"2024-03-13T17:44:06.602187Z","iopub.status.idle":"2024-03-13T17:44:07.019248Z","shell.execute_reply.started":"2024-03-13T17:44:06.602152Z","shell.execute_reply":"2024-03-13T17:44:07.018333Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"vi_vocab = vi_vectorization.get_vocabulary()\nvi_index_lookup = dict(zip(range(len(vi_vocab)), vi_vocab))\nmax_decoded_sentence_length = 40\n\ndef decode_sequence(input_sentence):\n    tokenized_input_sentence = en_vectorization([input_sentence])\n    decoded_sentence = '[start]'\n    for i in range(max_decoded_sentence_length):\n        tokenized_target_sentence = vi_vectorization([decoded_sentence])[:, :-1]\n        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n        \n        sampled_token_index = np.argmax(predictions[0, i, :])\n        sampled_token = vi_index_lookup[sampled_token_index]\n        decoded_sentence += ' ' + sampled_token\n        \n        if sampled_token == '[end]':\n            break\n    return decoded_sentence","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:24:06.816960Z","iopub.execute_input":"2024-03-13T17:24:06.817193Z","iopub.status.idle":"2024-03-13T17:24:06.894719Z","shell.execute_reply.started":"2024-03-13T17:24:06.817163Z","shell.execute_reply":"2024-03-13T17:24:06.893596Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"test_eng_texts = data_test2013_en[:10]\n\nfor i in range(10):\n    input_sentence = random.choice(test_eng_texts)\n    translated = decode_sequence(input_sentence)\n    print(f'{\"%02d\" % (i + 1)}: {input_sentence} ---> {translated}')","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:24:06.897940Z","iopub.execute_input":"2024-03-13T17:24:06.898637Z","iopub.status.idle":"2024-03-13T17:24:18.923009Z","shell.execute_reply.started":"2024-03-13T17:24:06.898603Z","shell.execute_reply":"2024-03-13T17:24:18.922317Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"01: although i often wondered about the outside world , i thought i would spend my entire life in north korea , until everything suddenly changed .  ---> [start] mặc dù tôi thường tự hỏi về thế giới bên ngoài tôi đã nghĩ tôi sẽ dành cả cuộc sống của tôi cho tới khi mọi thứ đột nhiên thay thế  mọi bất   nào mọi  \n02: my family was not poor , and myself , i had never experienced hunger .  ---> [start] gia đình tôi không phải là người nghèo và tôi đã không bao giờ trải nghiệm                        \n03: my family was not poor , and myself , i had never experienced hunger .  ---> [start] gia đình tôi không phải là người nghèo và tôi đã không bao giờ trải nghiệm                        \n04: it read , &quot when you read this , all five family members will not exist in this world , because we haven &apos t eaten for the past two weeks .  ---> [start] đọc khi bạn đọc tất cả những tác phẩm này được năm thành viên không tồn tại trong thế giới này bởi vì chúng ta chưa từng ăn trong suốt hai tuần qua       \n05: and i was very proud .  ---> [start] tôi rất tự hào                                    \n06: i was so shocked .  ---> [start]  tôi                                      \n07: it read , &quot when you read this , all five family members will not exist in this world , because we haven &apos t eaten for the past two weeks .  ---> [start] đọc khi bạn đọc tất cả những tác phẩm này được năm thành viên không tồn tại trong thế giới này bởi vì chúng ta chưa từng ăn trong suốt hai tuần qua       \n08: although i often wondered about the outside world , i thought i would spend my entire life in north korea , until everything suddenly changed .  ---> [start] mặc dù tôi thường tự hỏi về thế giới bên ngoài tôi đã nghĩ tôi sẽ dành cả cuộc sống của tôi cho tới khi mọi thứ đột nhiên thay thế  mọi bất   nào mọi  \n09: i was so shocked .  ---> [start]  tôi                                      \n10: it read , &quot when you read this , all five family members will not exist in this world , because we haven &apos t eaten for the past two weeks .  ---> [start] đọc khi bạn đọc tất cả những tác phẩm này được năm thành viên không tồn tại trong thế giới này bởi vì chúng ta chưa từng ăn trong suốt hai tuần qua       \n","output_type":"stream"}]},{"cell_type":"code","source":"test_eng_texts = data_test2013_en[10:30]\n\nfor i in range(20):\n    input_sentence = random.choice(test_eng_texts)\n    translated = decode_sequence(input_sentence)\n    print(f'{\"%02d\" % (i + 1)}: {input_sentence} ---> {translated}')","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:37:14.461418Z","iopub.execute_input":"2024-03-13T17:37:14.461700Z","iopub.status.idle":"2024-03-13T17:37:37.897904Z","shell.execute_reply.started":"2024-03-13T17:37:14.461672Z","shell.execute_reply":"2024-03-13T17:37:37.897173Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"01: this is the amrok river , which serves as a part of the border between north korea and china .  ---> [start] đây là dòng sông thu âm được một phần giữa bắc israel và trung quốc     giữa và       và       và     \n02: sometimes , i saw dead bodies floating down the river .  ---> [start] đôi khi tôi thấy được cơ thể đã bay trên sông                             \n03: i always wondered why they had lights but we didn &apos t .  ---> [start] luôn tự hỏi tại sao chúng ta có đèn nhưng chúng ta không                    không      không \n04: as you can see , the river can be very narrow at certain points , allowing north koreans to secretly cross .  ---> [start] như bạn có thể thấy sông ở những điểm rất nhỏ ở một vài điểm cho phép người bắc mỹ bạn đi qua những cuộc hội thoại             \n05: i could have never imagined that it would take 14 years to live together .  ---> [start] có thể không bao giờ tưởng tượng rằng sẽ sống được với nhau                           \n06: in china , it was hard living as a young girl without my family .  ---> [start] trung quốc đang sống khó khăn như một đứa trẻ mà không có gia đình tôi         của      của         \n07: i can &apos t reveal many details &#91 about &#93 how i left north korea , but i only can say that during the ugly years of the famine i was sent to china to live with distant relatives .  ---> [start] tôi không thể hiện nhiều chi tiết ở bắc iran tôi đã không thể hiện những gì tôi chỉ nói trong những năm gần đây của những người đói nghèo mà tôi gửi cho trung quốc với họ hàng xóm\n08: a huge famine hit north korea in the mid 1990s .  ---> [start] là một nạn đói lớn nhất bắc mỹ vào giữa thập kỷ 90                           \n09: i could have never imagined that it would take 14 years to live together .  ---> [start] có thể không bao giờ tưởng tượng rằng sẽ sống được với nhau                           \n10: sometimes , i saw dead bodies floating down the river .  ---> [start] đôi khi tôi thấy được cơ thể đã bay trên sông                             \n11: this was the first time i heard that people in my country were suffering .  ---> [start] được lần đầu tôi nghe thấy rằng ở người khác trong đất nước tôi phải chịu đựng                       \n12: but i only thought that i would be separated from my family for a short time .  ---> [start] tôi nghĩ tôi sẽ bị tách khỏi những ngôi nhà của mình trong một thời gian ngắn                       \n13: i always wondered why they had lights but we didn &apos t .  ---> [start] luôn tự hỏi tại sao chúng ta có đèn nhưng chúng ta không                    không      không \n14: this was the first time i heard that people in my country were suffering .  ---> [start] được lần đầu tôi nghe thấy rằng ở người khác trong đất nước tôi phải chịu đựng                       \n15: so i was living in constant fear that my identity could be revealed , and i would be repatriated to a horrible fate back in north korea .  ---> [start] tôi đang sống trong nỗi sợ hãi tự mình bị thay đổi  của tôi sẽ được tiết cho và trở một những thủ khủng khủng khủng ở bắc   và   đã trở cùng  ở bắc\n16: i always wondered why they had lights but we didn &apos t .  ---> [start] luôn tự hỏi tại sao chúng ta có đèn nhưng chúng ta không                    không      không \n17: so i was living in constant fear that my identity could be revealed , and i would be repatriated to a horrible fate back in north korea .  ---> [start] tôi đang sống trong nỗi sợ hãi tự mình bị thay đổi  của tôi sẽ được tiết cho và trở một những thủ khủng khủng khủng ở bắc   và   đã trở cùng  ở bắc\n18: i had no idea what life was going to be like as a north korean refugee , but i soon learned it &apos s not only extremely difficult , it &apos s also very dangerous , since north korean refugees are considered in china as illegal migrants .  ---> [start] tôi không biết ý định sẽ được là gì  như đây một tôi bắc iran nhưng tôi sớm tôi được học nó không là khó chỉ nó rất một rất đấu người khác trong [UNK] khi là một thủ\n19: so i was living in constant fear that my identity could be revealed , and i would be repatriated to a horrible fate back in north korea .  ---> [start] tôi đang sống trong nỗi sợ hãi tự mình bị thay đổi  của tôi sẽ được tiết cho và trở một những thủ khủng khủng khủng ở bắc   và   đã trở cùng  ở bắc\n20: but i only thought that i would be separated from my family for a short time .  ---> [start] tôi nghĩ tôi sẽ bị tách khỏi những ngôi nhà của mình trong một thời gian ngắn                       \n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}